{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#Machine Learning Library\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle           \n",
    "\n",
    "#Plotting Libraries\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "import matplotlib.pyplot as plt             \n",
    "\n",
    "#openCV\n",
    "import cv2                                 \n",
    "\n",
    "#Tensor Flow & Keras\n",
    "import tensorflow as tf    \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#Train & Test Data Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Garbage Collector\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral  파일 길이 :  6198\n",
      "angry  파일 길이 :  4953\n",
      "surprise  파일 길이 :  4002\n",
      "smile  파일 길이 :  8989\n",
      "sad  파일 길이 :  6077\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image # Python Image Library  (파이썬을 이용해서 쉽게 이미지 프로세싱을 할 수 있게 주는 라이브러리)\n",
    "import os # OS는 operating system의 약자로, 운영체제를 의미 파이썬에 기본적으로 내장된 모듈의 이름\n",
    "           # os.path 모듈은 파일명과 파일경로에 대한 유용한 함수들을 많이 제공함\n",
    "            # 경로의 이미지를 모두 뽑아내기 위한 os.listdir 사용예제\n",
    "        \n",
    "import glob # 재귀적으로 현재 폴더의 모든 하위폴더까지 탐색하여 확장자가 jpg인 파일을 출력한다.\n",
    "            # 특정 파일만 출력하기\n",
    "    \n",
    "import numpy as np # 계산을 위해 행렬과 같은 다양한 수학 도구를 사용하기 위한 라이브러리\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "caltech_dir = \"dataset/train\" # fire 데이터 폴더 경로\n",
    "categories = [\"neutral\",\"angry\",\"surprise\",\"smile\",\"sad\"]  # 각 dataset 폴더이름\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 48\n",
    "image_h = 48\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 입력값에 따른 결과값\n",
    "    # 분류 클래스 길이 만큼 선언한 뒤\n",
    "    # 속하는 클래스에 참 거짓(1,0) 표현\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "    \n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat #이미지가 있는 디렉터리 경로 설정\n",
    "    files = glob.glob(image_dir+\"/*.jpg\") # 이미지 파일 가져오기\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files): # 인덱스 번호와 컬렉션의 원소를 tuple형태로 반환\n",
    "#         img = Image.open(f) # f는 이미지의 경로를 찾아가서 이미지 열기\n",
    "#         img = img.convert(\"RGB\") #RGB 모드로 변환\n",
    "#         img = img.resize((image_w, image_h)) ## 이미지 크기 줄이기\n",
    "#         data = np.asarray(img) # 입력 데이터를 ndarray로 변환하나 이미 ndarray일 경우에는 새로 메모리에 ndarray가 생성되지 않음\n",
    "                              \n",
    "#                              # ndarray 클래스 객체는 C언어의 행렬처럼 연속적인 메모리 배치를 가지기 때문에 \n",
    "#                              # 모든 원소가 같은 자료형이어야 한다. \n",
    "#                              # 이러한 제약을 가지는 대신 내부의 원소에 대한 접근과 반복문 실행이 빨라진다.\n",
    "\n",
    "        view_img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "        view_img = cv2.cvtColor(view_img, cv2.COLOR_BGR2GRAY)\n",
    "        view_img = cv2.resize(view_img,(image_w, image_h))\n",
    "        view_img = cv2.split(view_img)\n",
    "        view_img = np.asarray(view_img)\n",
    "#         view_img = cv2.split(view_img)\n",
    "\n",
    "#         print(cv2.split(view_img)[0].shape)\n",
    "#         b, g, r = cv2.split(view_img) # img파일을 색 채널별 b,g,r로 분리\n",
    "#         data = cv2.merge([r,g,b])\n",
    "#         data = np.asarray(data)\n",
    "\n",
    "\n",
    "\n",
    "        X.append(view_img)\n",
    "        y.append(label)\n",
    "\n",
    "#         if i % 3000 == 0:\n",
    "#             print(cat, \" : \", f)\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# #dataset을 train data와 validation data를 나누어주는 함수\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# xy = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# np.save(\"dataset/Predict_Facial_Expressions.npy\", xy) #1개의 배열을 NumPy format의 바이너리 파일로 저장하기\n",
    "\n",
    "# print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-e8a436ab3950>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "N = X.shape\n",
    "X = X.reshape(N, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48)\n",
      "(30219, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "print(view_img.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "# 입력 파일 지정하기\n",
    "\n",
    "caltech_dir = \"nota/train/img\" # fire 데이터 폴더 경로\n",
    "files = glob.glob(caltech_dir+\"/*.jpg\") # 이미지 파일 가져오기\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 캐스케이드 파일의 경로 지정하기 --- (※1)\n",
    "cascade_file = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "\n",
    "for i, f in enumerate(files): # 인덱스 번호와 컬렉션의 원소를 tuple형태로 반환\n",
    "    view_img = cv2.imread(f, cv2.COLOR_BGR2GRAY)\n",
    "    face_extractor(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 이미지 읽어 들이기 --- (※2)\n",
    "image = cv2.imread(image_file)\n",
    "# 그레이스케일로 변환하기\n",
    "image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# 얼굴 인식 특징 파일 읽어 들이기 --- (※3)\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "# 얼굴 인식 실행하기\n",
    "face_list = cascade.detectMultiScale(image_gs,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=1,\n",
    "    minSize=(150,150))\n",
    "if len(face_list) > 0:\n",
    "    # 인식한 부분 표시하기 --- (※4)\n",
    "    print(face_list)\n",
    "    color = (0, 0, 255)\n",
    "    for face in face_list:\n",
    "        x,y,w,h = face\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), color, thickness=8)\n",
    "    # 파일로 출력하기 --- (※5)\n",
    "    cv2.imwrite(\"facedetect-output.PNG\", image)\n",
    "else:\n",
    "    print(\"no face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#전체 사진에서 얼굴 부위만 잘라 리턴\n",
    "def face_extractor(img):\n",
    "    global count\n",
    "    \n",
    "    #흑백처리 \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #얼굴 찾기 \n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    #찾은 얼굴이 없으면 None으로 리턴 \n",
    "    if faces is():\n",
    "        return None\n",
    "    #얼굴들이 있으면 \n",
    "    for(x,y,w,h) in faces:\n",
    "        #해당 얼굴 크기만큼 cropped_face에 잘라 넣기 \n",
    "        #근데... 얼굴이 2개 이상 감지되면??\n",
    "        #가장 마지막의 얼굴만 남을 듯\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        face = cv2.resize(cropped_face,(200,200))\n",
    "        cv2.imwrite('facetest/face_test'+str(count)+'.jpg',face)\n",
    "        count+=1\n",
    "    #cropped_face 리턴 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
